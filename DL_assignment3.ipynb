{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n#physical_devices = tf.config.list_physical_devices('GPU')\n#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\ntf.test.gpu_device_name()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T02:43:47.603849Z","iopub.execute_input":"2022-05-05T02:43:47.604319Z","iopub.status.idle":"2022-05-05T02:43:53.548260Z","shell.execute_reply.started":"2022-05-05T02:43:47.604280Z","shell.execute_reply":"2022-05-05T02:43:53.547649Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:29.667988Z","iopub.execute_input":"2022-05-05T02:44:29.668637Z","iopub.status.idle":"2022-05-05T02:44:29.672039Z","shell.execute_reply.started":"2022-05-05T02:44:29.668602Z","shell.execute_reply":"2022-05-05T02:44:29.671227Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"target_language = \"bn\"\nPATH_template = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/{}/lexicons/{}.translit.sampled.{}.tsv\"\ntrain_path = PATH_template.format(target_language, target_language, \"train\")\ndev_path = PATH_template.format(target_language, target_language, \"dev\")\ntest_path = PATH_template.format(target_language, target_language, \"test\")\n\ntrain_data = pd.read_csv(train_path, sep = '\\t', header = None)\ndev_data = pd.read_csv(dev_path, sep = '\\t', header = None)\ntest_data = pd.read_csv(test_path, sep = '\\t', header = None)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:31.608682Z","iopub.execute_input":"2022-05-05T02:44:31.608954Z","iopub.status.idle":"2022-05-05T02:44:31.842861Z","shell.execute_reply.started":"2022-05-05T02:44:31.608925Z","shell.execute_reply":"2022-05-05T02:44:31.841736Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#word wise list\ntrain_input = [str(w) for w in train_data[1]]\ntrain_target = [\"\\t\" + str(w) + \"\\n\" for w in train_data[0]]\n\ndev_input = [str(w) for w in dev_data[1]]\ndev_target = [\"\\t\" + str(w) + \"\\n\" for w in dev_data[0]]\n\ntest_input = [str(w) for w in test_data[1]]\ntest_target = [\"\\t\" + str(w) + \"\\n\" for w in test_data[0]]","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:32.258345Z","iopub.execute_input":"2022-05-05T02:44:32.258983Z","iopub.status.idle":"2022-05-05T02:44:32.366389Z","shell.execute_reply.started":"2022-05-05T02:44:32.258941Z","shell.execute_reply":"2022-05-05T02:44:32.365709Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"input_characters = set()\ntarget_characters = set()\ninput_characters.add(' ')\ntarget_characters.add(' ')\n\nfor word in train_input:\n    for char in word:\n        input_characters.add(char)\nfor word in dev_input:\n    for char in word:\n        input_characters.add(char)\nfor word in test_input:\n    for char in word:\n        input_characters.add(char)\n\nfor word in train_target:\n    for char in word:\n        target_characters.add(char)\nfor word in dev_target:\n    for char in word:\n        target_characters.add(char)\nfor word in test_target:\n    for char in word:\n        target_characters.add(char)\n\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max(max([len(txt) for txt in train_input]),max([len(txt) for txt in dev_input]))\nmax_decoder_seq_length = max(max([len(txt) for txt in train_target]),max([len(txt) for txt in dev_target]))\n\nprint(\"Number of samples:\", len(train_input))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"Max sequence length for inputs:\", max_encoder_seq_length)\nprint(\"Max sequence length for outputs:\", max_decoder_seq_length)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:32.574377Z","iopub.execute_input":"2022-05-05T02:44:32.574895Z","iopub.status.idle":"2022-05-05T02:44:33.102043Z","shell.execute_reply.started":"2022-05-05T02:44:32.574853Z","shell.execute_reply":"2022-05-05T02:44:33.101035Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(input_characters)\nprint(target_characters)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:33.880357Z","iopub.execute_input":"2022-05-05T02:44:33.881532Z","iopub.status.idle":"2022-05-05T02:44:33.888289Z","shell.execute_reply.started":"2022-05-05T02:44:33.881450Z","shell.execute_reply":"2022-05-05T02:44:33.887027Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\ntarget_token_index = dict([(char, i) for i, char in enumerate(target_characters)])","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:35.099510Z","iopub.execute_input":"2022-05-05T02:44:35.100450Z","iopub.status.idle":"2022-05-05T02:44:35.105026Z","shell.execute_reply.started":"2022-05-05T02:44:35.100408Z","shell.execute_reply":"2022-05-05T02:44:35.104386Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(input_token_index)\nprint(target_token_index)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:35.551972Z","iopub.execute_input":"2022-05-05T02:44:35.553139Z","iopub.status.idle":"2022-05-05T02:44:35.558584Z","shell.execute_reply.started":"2022-05-05T02:44:35.553081Z","shell.execute_reply":"2022-05-05T02:44:35.557771Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Training encoder-decoder","metadata":{}},{"cell_type":"code","source":"train_encoder_input_data = np.zeros((len(train_input), max_encoder_seq_length), dtype=\"float32\")\ntrain_decoder_input_data = np.zeros((len(train_input), max_decoder_seq_length), dtype=\"float32\")\ntrain_decoder_target_data = np.zeros((len(train_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:36.926224Z","iopub.execute_input":"2022-05-05T02:44:36.926661Z","iopub.status.idle":"2022-05-05T02:44:36.931658Z","shell.execute_reply.started":"2022-05-05T02:44:36.926631Z","shell.execute_reply":"2022-05-05T02:44:36.930968Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(train_encoder_input_data.shape)\nprint(train_decoder_input_data.shape)\nprint(train_decoder_target_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:38.221896Z","iopub.execute_input":"2022-05-05T02:44:38.222182Z","iopub.status.idle":"2022-05-05T02:44:38.227700Z","shell.execute_reply.started":"2022-05-05T02:44:38.222149Z","shell.execute_reply":"2022-05-05T02:44:38.226589Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for i, (input_text, target_text) in enumerate(zip(train_input, train_target)):\n    for t, char in enumerate(input_text):\n        train_encoder_input_data[i, t] = input_token_index[char]\n    train_encoder_input_data[i, t + 1 :] = input_token_index[' ']\n    for t, char in enumerate(target_text):\n        train_decoder_input_data[i, t] = target_token_index[char]\n        if t > 0:\n            train_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n    train_decoder_input_data[i, t + 1 :] = target_token_index[' ']\n    train_decoder_target_data[i, t:, target_token_index[' ']] =  1.0","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:54.657551Z","iopub.execute_input":"2022-05-05T02:44:54.658356Z","iopub.status.idle":"2022-05-05T02:44:56.857520Z","shell.execute_reply.started":"2022-05-05T02:44:54.658298Z","shell.execute_reply":"2022-05-05T02:44:56.856446Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_decoder_target_data","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:44:58.757557Z","iopub.execute_input":"2022-05-05T02:44:58.757832Z","iopub.status.idle":"2022-05-05T02:44:58.768233Z","shell.execute_reply.started":"2022-05-05T02:44:58.757801Z","shell.execute_reply":"2022-05-05T02:44:58.767497Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Validation Encoder- decoder","metadata":{}},{"cell_type":"code","source":"dev_encoder_input_data = np.zeros((len(dev_input), max_encoder_seq_length), dtype=\"float32\")\ndev_decoder_input_data = np.zeros((len(dev_input), max_decoder_seq_length), dtype=\"float32\")\ndev_decoder_target_data = np.zeros((len(dev_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:45:04.633750Z","iopub.execute_input":"2022-05-05T02:45:04.634671Z","iopub.status.idle":"2022-05-05T02:45:04.641622Z","shell.execute_reply.started":"2022-05-05T02:45:04.634611Z","shell.execute_reply":"2022-05-05T02:45:04.640741Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(dev_encoder_input_data.shape)\nprint(dev_decoder_input_data.shape)\nprint(dev_decoder_target_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:45:05.760118Z","iopub.execute_input":"2022-05-05T02:45:05.760494Z","iopub.status.idle":"2022-05-05T02:45:05.767538Z","shell.execute_reply.started":"2022-05-05T02:45:05.760457Z","shell.execute_reply":"2022-05-05T02:45:05.766385Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for i, (input_text, target_text) in enumerate(zip(dev_input, dev_target)):\n    for t, char in enumerate(input_text):\n        dev_encoder_input_data[i, t] = input_token_index[char]\n    dev_encoder_input_data[i, t + 1 :] = input_token_index[' ']\n    for t, char in enumerate(target_text):\n        dev_decoder_input_data[i, t] = target_token_index[char]\n        if t > 0:\n            dev_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n    dev_decoder_input_data[i, t + 1 :] = target_token_index[' ']\n    dev_decoder_target_data[i, t:, target_token_index[' '] ] = 1.0","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:45:12.126556Z","iopub.execute_input":"2022-05-05T02:45:12.126890Z","iopub.status.idle":"2022-05-05T02:45:12.346523Z","shell.execute_reply.started":"2022-05-05T02:45:12.126857Z","shell.execute_reply":"2022-05-05T02:45:12.345565Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"batch_size = 64  # Batch size for training.\nepochs = 20  # Number of epochs to train for.\nlatent_dim = 256  # Latent dimensionality of the encoding space.\nnum_samples = len(train_input)  # Number of samples to train on.\nembedding_size = 256\ndropout = 0.2\nmodel_name = \"GRU\"\nencoder_layers = 3\ndecoder_layers = 2","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:48:00.444072Z","iopub.execute_input":"2022-05-05T02:48:00.444486Z","iopub.status.idle":"2022-05-05T02:48:00.451046Z","shell.execute_reply.started":"2022-05-05T02:48:00.444452Z","shell.execute_reply":"2022-05-05T02:48:00.450289Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"encoder_inputs = keras.Input(shape=(None, ))\nencoder_outputs = keras.layers.Embedding(input_dim = num_encoder_tokens,\n                                         output_dim = embedding_size,\n                                         input_length = max_encoder_seq_length)(encoder_inputs)\n\nfor _ in range(encoder_layers):\n    if model_name == \"RNN\":\n        encoder_outputs, state = keras.layers.SimpleRNN(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n        encoder_states = [state]\n    elif model_name == \"LSTM\":\n        encoder_outputs, state_h, state_c = keras.layers.LSTM(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n        encoder_states = [state_h, state_c]\n    elif model_name == \"GRU\":\n        encoder_outputs, state = keras.layers.GRU(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n        encoder_states = [state]\n    \n# encoder = (latent_dim, return_state=True)\n# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n\n# # We discard `encoder_outputs` and only keep the states.\n# encoder_states = [state_h, state_c]\n\ndecoder_inputs = keras.Input(shape=(None, ))\ndecoder_outputs = keras.layers.Embedding(input_dim = num_decoder_tokens, output_dim = embedding_size, input_length = max_decoder_seq_length)(decoder_inputs)\n\nfor _ in range(decoder_layers):\n    if model_name == \"RNN\":\n        decoder = keras.layers.SimpleRNN(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n        decoder_outputs, _ = decoder(decoder_outputs, initial_state = encoder_states)\n\n    elif model_name == \"LSTM\":\n        decoder = keras.layers.LSTM(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n        decoder_outputs, _, _ = decoder(decoder_outputs, initial_state = encoder_states)\n\n    elif model_name == \"GRU\":\n        decoder = keras.layers.GRU(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n        decoder_outputs, _= decoder(decoder_outputs, initial_state = encoder_states)\n    \n\n# Set up the decoder, using `encoder_states` as initial state.\n# decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\n# decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n# decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:48:03.341886Z","iopub.execute_input":"2022-05-05T02:48:03.343126Z","iopub.status.idle":"2022-05-05T02:48:04.462631Z","shell.execute_reply.started":"2022-05-05T02:48:03.343049Z","shell.execute_reply":"2022-05-05T02:48:04.461826Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:48:12.527236Z","iopub.execute_input":"2022-05-05T02:48:12.528145Z","iopub.status.idle":"2022-05-05T02:48:12.541320Z","shell.execute_reply.started":"2022-05-05T02:48:12.528098Z","shell.execute_reply":"2022-05-05T02:48:12.540635Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n)\nmodel.fit(\n    [train_encoder_input_data, train_decoder_input_data],\n    train_decoder_target_data,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_data = ([dev_encoder_input_data, dev_decoder_input_data], dev_decoder_target_data),\n)\n# Save model\nmodel.save(\"s2s\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T02:48:28.668562Z","iopub.execute_input":"2022-05-05T02:48:28.668875Z","iopub.status.idle":"2022-05-05T04:28:02.948619Z","shell.execute_reply.started":"2022-05-05T02:48:28.668842Z","shell.execute_reply":"2022-05-05T04:28:02.947756Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T04:28:07.691917Z","iopub.execute_input":"2022-05-05T04:28:07.692344Z","iopub.status.idle":"2022-05-05T04:28:08.795989Z","shell.execute_reply.started":"2022-05-05T04:28:07.692299Z","shell.execute_reply":"2022-05-05T04:28:08.795239Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# **Inference**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}