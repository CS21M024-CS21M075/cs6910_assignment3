{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Vanilla Mechanism Best Model Run Code","metadata":{}},{"cell_type":"markdown","source":"**Submitted By:**\nJoyojyoti Acharya - CS21M024,\nVrushab Karia - CS21M075","metadata":{}},{"cell_type":"markdown","source":"### Importing the Necessary Packages","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom tensorflow import keras\ntf.test.gpu_device_name()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:03:40.464704Z","iopub.execute_input":"2022-05-07T14:03:40.465539Z","iopub.status.idle":"2022-05-07T14:03:47.867350Z","shell.execute_reply.started":"2022-05-07T14:03:40.465431Z","shell.execute_reply":"2022-05-07T14:03:47.866144Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Importing Dataset","metadata":{}},{"cell_type":"code","source":"#Using target Language as Hindi\ntarget_language = \"hi\"\nDATAPATH = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/{}/lexicons/{}.translit.sampled.{}.tsv\"\n\n#Defining training, validation and test path and reading the data from dataset.\n\n#Training\ntrain_path = DATAPATH.format(target_language, target_language, \"train\")\ntrain_data = pd.read_csv(train_path, sep = '\\t', header = None)\n\n#Validation\ndev_path = DATAPATH.format(target_language, target_language, \"dev\")\ndev_data = pd.read_csv(dev_path, sep = '\\t', header = None)\n\n#Test\ntest_path = DATAPATH.format(target_language, target_language, \"test\")\ntest_data = pd.read_csv(test_path, sep = '\\t', header = None)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:03:53.587737Z","iopub.execute_input":"2022-05-07T14:03:53.588054Z","iopub.status.idle":"2022-05-07T14:03:53.708538Z","shell.execute_reply.started":"2022-05-07T14:03:53.588026Z","shell.execute_reply":"2022-05-07T14:03:53.707497Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Spliting the dataset into wordwise and characterwise","metadata":{}},{"cell_type":"code","source":"#All unique characters\ninput_characters = set()\ntarget_characters = set()\ninput_characters.add(' ')\ntarget_characters.add(' ')\n\n#Training Data\ntrain_input = [str(w) for w in train_data[1]]\ntrain_target = [\"\\t\" + str(w) + \"\\n\" for w in train_data[0]]\nfor word in train_input:\n    for char in word:\n        input_characters.add(char)\nfor word in train_target:\n    for char in word:\n        target_characters.add(char)\n\n#Validation Data\ndev_input = [str(w) for w in dev_data[1]]\ndev_target = [\"\\t\" + str(w) + \"\\n\" for w in dev_data[0]]\nfor word in dev_input:\n    for char in word:\n        input_characters.add(char)\nfor word in dev_target:\n    for char in word:\n        target_characters.add(char)\n\n#Test Data\ntest_input = [str(w) for w in test_data[1]]\ntest_target = [\"\\t\" + str(w) + \"\\n\" for w in test_data[0]]\n\nfor word in test_input:\n    for char in word:\n        input_characters.add(char) \nfor word in test_target:\n    for char in word:\n        target_characters.add(char)\n        \n#Sorting the characters\ninput_characters = list(input_characters)\ntarget_characters = list(target_characters)\ninput_characters.sort()\ntarget_characters.sort()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:03:54.651131Z","iopub.execute_input":"2022-05-07T14:03:54.651731Z","iopub.status.idle":"2022-05-07T14:03:54.844734Z","shell.execute_reply.started":"2022-05-07T14:03:54.651640Z","shell.execute_reply":"2022-05-07T14:03:54.843754Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Fetching character and maximum sequence length","metadata":{}},{"cell_type":"code","source":"num_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max(max([len(text) for text in train_input]),max([len(text) for text in dev_input]))\nmax_encoder_seq_length = max(max_encoder_seq_length,max([len(text) for text in test_input]))\n                             \nmax_decoder_seq_length = max(max([len(text) for text in train_target]),max([len(text) for text in dev_target]))\nmax_decoder_seq_length = max(max_decoder_seq_length,max([len(text) for text in test_target]))\n                             \nprint(\"Number of Training samples:\", len(train_input))\nprint(\"Number of Validation samples:\", len(dev_input))\nprint(\"Number of Test samples:\", len(test_input))\n                             \nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"Max sequence length for inputs:\", max_encoder_seq_length)\nprint(\"Max sequence length for outputs:\", max_decoder_seq_length)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:03:55.624995Z","iopub.execute_input":"2022-05-07T14:03:55.625922Z","iopub.status.idle":"2022-05-07T14:03:55.650914Z","shell.execute_reply.started":"2022-05-07T14:03:55.625875Z","shell.execute_reply":"2022-05-07T14:03:55.648925Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Dictionary Indexing and Inverse Dictionary Indexing for the unique Characters","metadata":{}},{"cell_type":"code","source":"input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\ninverse_input_token_index = dict([(i, char) for i, char in enumerate(input_characters)])\ntarget_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\ninverse_target_token_index = dict([(i, char) for i, char in enumerate(target_characters)])","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:03:56.965406Z","iopub.execute_input":"2022-05-07T14:03:56.965789Z","iopub.status.idle":"2022-05-07T14:03:56.972898Z","shell.execute_reply.started":"2022-05-07T14:03:56.965754Z","shell.execute_reply":"2022-05-07T14:03:56.971540Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Training Encoder-Decoder One Hot Data Preparation","metadata":{}},{"cell_type":"code","source":"train_encoder_input_data = np.zeros((len(train_input), max_encoder_seq_length), dtype=\"float32\")\ntrain_decoder_input_data = np.zeros((len(train_input), max_decoder_seq_length), dtype=\"float32\")\ntrain_decoder_target_data = np.zeros((len(train_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\nfor i, (input_text, target_text) in enumerate(zip(train_input, train_target)):\n    for t, char in enumerate(input_text):\n        train_encoder_input_data[i, t] = input_token_index[char]\n    train_encoder_input_data[i, t + 1 :] = input_token_index[' ']\n    for t, char in enumerate(target_text):\n        train_decoder_input_data[i, t] = target_token_index[char]\n        if t > 0:\n            train_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n    train_decoder_input_data[i, t + 1 :] = target_token_index[' ']\n    train_decoder_target_data[i, t:, target_token_index[' ']] =  1.0","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:03:57.859184Z","iopub.execute_input":"2022-05-07T14:03:57.859468Z","iopub.status.idle":"2022-05-07T14:03:58.738437Z","shell.execute_reply.started":"2022-05-07T14:03:57.859438Z","shell.execute_reply":"2022-05-07T14:03:58.737518Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Validation Encoder-Decoder One Hot Data Preparation","metadata":{}},{"cell_type":"code","source":"dev_encoder_input_data = np.zeros((len(dev_input), max_encoder_seq_length), dtype=\"float32\")\ndev_decoder_input_data = np.zeros((len(dev_input), max_decoder_seq_length), dtype=\"float32\")\ndev_decoder_target_data = np.zeros((len(dev_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\nfor i, (input_text, target_text) in enumerate(zip(dev_input, dev_target)):\n    for t, char in enumerate(input_text):\n        dev_encoder_input_data[i, t] = input_token_index[char]\n    dev_encoder_input_data[i, t + 1 :] = input_token_index[' ']\n    for t, char in enumerate(target_text):\n        dev_decoder_input_data[i, t] = target_token_index[char]\n        if t > 0:\n            dev_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n    dev_decoder_input_data[i, t + 1 :] = target_token_index[' ']\n    dev_decoder_target_data[i, t:, target_token_index[' '] ] = 1.0","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:03:58.858081Z","iopub.execute_input":"2022-05-07T14:03:58.858871Z","iopub.status.idle":"2022-05-07T14:03:58.963216Z","shell.execute_reply.started":"2022-05-07T14:03:58.858808Z","shell.execute_reply":"2022-05-07T14:03:58.961960Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Test Data setup","metadata":{}},{"cell_type":"code","source":"test_encoder_input_data = np.zeros((len(test_input), max_encoder_seq_length), dtype=\"float32\")\nfor i, input_word in enumerate(test_input):\n    for t, char in enumerate(input_word):\n        test_encoder_input_data[i, t] = input_token_index[char]\n    test_encoder_input_data[i, t + 1 :] = input_token_index[' ']","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:03:59.665441Z","iopub.execute_input":"2022-05-07T14:03:59.665766Z","iopub.status.idle":"2022-05-07T14:03:59.698392Z","shell.execute_reply.started":"2022-05-07T14:03:59.665712Z","shell.execute_reply":"2022-05-07T14:03:59.697510Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Wordwise Inference Mechanism for Vanilla Approach","metadata":{}},{"cell_type":"code","source":"#Sigmoid Function\ndef sigmoid(i):\n    return [1/(1 + np.exp(-z)) for z in i]\n\n# Vanilla_Inference Function\ndef vanilla_inference(model, dev_encoder_input_data, dev_input, dev_target, num_decoder_tokens, max_decoder_seq_length, target_token_index, inverse_target_token_index, encoder_latent_dim, decoder_latent_dim, model_name):\n    \n    #Prediction Function --> Wordwise\n    def decode_sequence_predict(input_sequence):\n        # Encode the input as state vectors.\n        states_value = [encoder_model.predict(input_sequence)] * len(decoder_models_index)\n        # Generate empty target sequence of length 1.\n        target_sequence = np.zeros(( 1, 1))\n\n        # Populate the first character of target sequence with the start character.\n        target_sequence[0, 0 ] = target_token_index[\"\\t\"]\n        \n        flag = True\n        output_sequence = \"\"\n\n        while flag:\n            output = decoder_model.predict([target_sequence] + states_value)\n            output_tokens, states_value = output[0], output[1:]\n\n            # Sample a token\n            sample_token_index = np.argmax(output_tokens[0, -1, :])\n            sample_chararcter = inverse_target_token_index[sample_token_index]\n            output_sequence += sample_chararcter\n            if sample_chararcter == \"\\n\" or len(output_sequence) > max_decoder_seq_length:\n                flag = False\n            target_sequence = np.zeros((1, 1))\n            target_sequence[0, 0] = sample_token_index \n        return output_sequence\n    \n    \n    no_of_encoder_layers = len(encoder_latent_dim)\n    encoder_embedding_index, encoder_models_index = -1, []\n    decoder_embedding_index, decoder_models_index = -1, []\n    dense_index = -1\n    encoder_layers_count = 0\n    \n    flag = True\n    for idx, layer in enumerate(model.layers):\n        print(layer.name)\n        # Dense Layer\n        if \"dense\" in layer.name :\n            dense_index = idx\n\n        # Embedding layer\n        if \"embedding\" in layer.name:\n            if flag:\n                encoder_embedding_index = idx\n                flag = False\n            else:\n                decoder_embedding_index = idx\n\n        # Encoder-Decoder Model Layers \n        if model_name.lower() in layer.name:\n            if encoder_layers_count < no_of_encoder_layers:\n                encoder_models_index.append(idx)\n                encoder_layers_count += 1\n            else:\n                decoder_models_index.append(idx)\n\n    \n    # Encoder Model\n    encoder_inputs = model.input[0]  # input_1\n\n    if model_name == \"RNN\" or model_name == \"GRU\":\n        encoder_outputs, state = model.layers[encoder_models_index[-1]].output\n        encoder_model = keras.Model(encoder_inputs, [state])\n    \n    elif model_name == \"LSTM\":\n        encoder_outputs, state_h_enc, state_c_enc = model.layers[encoder_models_index[-1]].output\n        encoder_model = keras.Model(encoder_inputs, [state_h_enc, state_c_enc])\n    \n    else:\n        print(\"Wrong Choice of Model...\")\n        return\n\n    #Decoder Model\n    decoder_inputs = model.input[1]  # input_2\n    decoder_outputs =  model.layers[decoder_embedding_index](decoder_inputs)\n\n    decoder_states_inputs =  []\n    decoder_states = []\n\n    # Decoder Models\n    for dec in range(len(decoder_latent_dim)):\n        \n        if model_name == \"RNN\" or model_name == \"GRU\":\n            state = keras.Input(shape = (decoder_latent_dim[dec], ))\n            current_states_inputs = [state]\n            decoder_outputs, state = model.layers[decoder_models_index[dec]](decoder_outputs, initial_state = current_states_inputs)\n            decoder_states += [state]\n\n        elif model_name == \"LSTM\":\n            state_h_dec, state_c_dec = keras.Input(shape = (decoder_latent_dim[dec],)),  keras.Input(shape = (decoder_latent_dim[dec],))\n            current_states_inputs = [state_h_dec, state_c_dec]\n            decoder_outputs, state_h_dec,state_c_dec = model.layers[decoder_models_index[dec]](decoder_outputs, initial_state = current_states_inputs)\n            decoder_states += [state_h_dec, state_c_dec]\n            \n        else:\n            print(\"Wrong Choice of Model...\")\n        \n        decoder_states_inputs += current_states_inputs\n\n    # Decoder Dense layer\n    decoder_dense = model.layers[dense_index]\n    decoder_outputs = decoder_dense(decoder_outputs)\n\n    # Final decoder model\n    decoder_model = keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n\n    #Count of correct Predictions\n    correct_count = 0\n    #File to Laod the Prediction\n    vanilla_prediction = open(\"/kaggle/working/predictions_vanilla.csv\", \"w\", encoding='utf-8')\n    vanilla_prediction.write(\"Input Sentence,Original Target Sentence,Predicted Output Sentence\\n\")\n    for idx in range(len(dev_input)):\n        if idx%50 == 0:\n            print(\"Test at: \", idx)\n        input_sequence = dev_encoder_input_data[idx : idx + 1]\n        decoded_word = decode_sequence_predict(input_sequence)\n        original_word = dev_target[idx][1:]\n        vanilla_prediction.write(dev_input[idx] + \",\" + decoded_word[:-1] + \",\" + original_word[:-1] + \"\\n\")\n        if(original_word == decoded_word):\n            correct_count += 1\n\n    return correct_count/len(dev_input)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:04:01.476050Z","iopub.execute_input":"2022-05-07T14:04:01.476825Z","iopub.status.idle":"2022-05-07T14:04:01.520141Z","shell.execute_reply.started":"2022-05-07T14:04:01.476775Z","shell.execute_reply":"2022-05-07T14:04:01.519122Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Main Block to Train the Best Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n\n#Best Configuration\nhidden_layer_size=512\nnum_encoder_layers=3\nnum_decoder_layers=3\nlearning_rate=0.001\noptimizer='nadam'\nbatch_size=64\nmodel_name = \"LSTM\"\nembedding_size = 512\ndropout = 0.3\nepochs = 25\nbeam_size = 0\n\n#Encoder Model\nencoder_inputs = keras.Input(shape=(None, ))\nencoder_outputs = keras.layers.Embedding(input_dim = num_encoder_tokens,\n                                        output_dim = embedding_size,\n                                        input_length = max_encoder_seq_length)(encoder_inputs)\n    \nencoder_latent_dim = [hidden_layer_size]*num_encoder_layers\nfor latent_dim in encoder_latent_dim:\n    if model_name == \"RNN\":\n        encoder_outputs, state = keras.layers.SimpleRNN(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n        encoder_states = [state]\n    elif model_name == \"LSTM\":\n        encoder_outputs, state_h, state_c = keras.layers.LSTM(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n        encoder_states = [state_h, state_c]\n    elif model_name == \"GRU\":\n        encoder_outputs, state = keras.layers.GRU(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n        encoder_states = [state]\n    else:\n        print(\"Wrong Choice of Model...\")\n\n#Decoder Model\ndecoder_inputs = keras.Input(shape=(None, ))\ndecoder_outputs = keras.layers.Embedding(input_dim = num_decoder_tokens,\n                                         output_dim = embedding_size, \n                                         input_length = max_decoder_seq_length)(decoder_inputs)\n\ndecoder_latent_dim = [hidden_layer_size]*num_decoder_layers\nfor latent_dim in decoder_latent_dim:\n    if model_name == \"RNN\":\n        decoder = keras.layers.SimpleRNN(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n        decoder_outputs, _ = decoder(decoder_outputs, initial_state = encoder_states)\n\n    elif model_name == \"LSTM\":\n        decoder = keras.layers.LSTM(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n        decoder_outputs, _, _ = decoder(decoder_outputs, initial_state = encoder_states)\n\n    elif model_name == \"GRU\":\n        decoder = keras.layers.GRU(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n        decoder_outputs, _= decoder(decoder_outputs, initial_state = encoder_states)\n    else:\n        print(\"Wrong Model Choice\")\n\n#Decoder Dense Layer\ndecoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Runnable Model\nmodel = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.summary()\n\n#Different Optimizers\nif optimizer == 'adam':\n    model.compile(optimizer = Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics = ['accuracy'])\nelif optimizer == 'nadam':\n    model.compile(optimizer = Nadam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics = ['accuracy'])\nelif optimizer == 'rmsprop':\n    model.compile(optimizer = RMSprop(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics = ['accuracy'])\nelse:\n    print(\"Wrong Optimizer Choice...\")\n        \n#Model fitting with train and validation data characterwise\nmodel.fit(\n    [train_encoder_input_data, train_decoder_input_data],\n    train_decoder_target_data,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_data = ([dev_encoder_input_data, dev_decoder_input_data], dev_decoder_target_data),\n)\nmodel.save(\"Best_Model\")\nvalidation_accuracy = vanilla_inference(model, dev_encoder_input_data, dev_input, dev_target, num_decoder_tokens, max_decoder_seq_length, target_token_index, inverse_target_token_index, encoder_latent_dim, decoder_latent_dim, model_name)\nprint(\"Wordlevel Validation Accuracy: \", validation_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:04:02.714504Z","iopub.execute_input":"2022-05-07T14:04:02.714810Z","iopub.status.idle":"2022-05-07T14:59:42.007469Z","shell.execute_reply.started":"2022-05-07T14:04:02.714782Z","shell.execute_reply":"2022-05-07T14:59:42.006404Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Test Accuracy on the Best Model","metadata":{}},{"cell_type":"code","source":"test_accuracy = vanilla_inference(model, test_encoder_input_data, test_input, test_target, num_decoder_tokens, max_decoder_seq_length, target_token_index, inverse_target_token_index, encoder_latent_dim, decoder_latent_dim, model_name)\nprint(\"Wordlevel Test Accuracy: \", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:59:42.009507Z","iopub.execute_input":"2022-05-07T14:59:42.010065Z","iopub.status.idle":"2022-05-07T15:42:17.617237Z","shell.execute_reply.started":"2022-05-07T14:59:42.010011Z","shell.execute_reply":"2022-05-07T15:42:17.616279Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/working/predictions_vanilla.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:42:17.620485Z","iopub.execute_input":"2022-05-07T15:42:17.621387Z","iopub.status.idle":"2022-05-07T15:42:17.644340Z","shell.execute_reply.started":"2022-05-07T15:42:17.621308Z","shell.execute_reply":"2022-05-07T15:42:17.642204Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:42:17.649617Z","iopub.execute_input":"2022-05-07T15:42:17.651521Z","iopub.status.idle":"2022-05-07T15:42:17.691817Z","shell.execute_reply.started":"2022-05-07T15:42:17.651468Z","shell.execute_reply":"2022-05-07T15:42:17.690418Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}