{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Mechanism Best Model Run Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submitted By:**\n",
    "Joyojyoti Acharya - CS21M024,\n",
    "Vrushab Karia - CS21M075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:03:40.465539Z",
     "iopub.status.busy": "2022-05-07T14:03:40.464704Z",
     "iopub.status.idle": "2022-05-07T14:03:47.867350Z",
     "shell.execute_reply": "2022-05-07T14:03:47.866144Z",
     "shell.execute_reply.started": "2022-05-07T14:03:40.465431Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:03:53.588054Z",
     "iopub.status.busy": "2022-05-07T14:03:53.587737Z",
     "iopub.status.idle": "2022-05-07T14:03:53.708538Z",
     "shell.execute_reply": "2022-05-07T14:03:53.707497Z",
     "shell.execute_reply.started": "2022-05-07T14:03:53.588026Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using target Language as Hindi\n",
    "target_language = \"hi\"\n",
    "DATAPATH = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/{}/lexicons/{}.translit.sampled.{}.tsv\"\n",
    "\n",
    "#Defining training, validation and test path and reading the data from dataset.\n",
    "\n",
    "#Training\n",
    "train_path = DATAPATH.format(target_language, target_language, \"train\")\n",
    "train_data = pd.read_csv(train_path, sep = '\\t', header = None)\n",
    "\n",
    "#Validation\n",
    "dev_path = DATAPATH.format(target_language, target_language, \"dev\")\n",
    "dev_data = pd.read_csv(dev_path, sep = '\\t', header = None)\n",
    "\n",
    "#Test\n",
    "test_path = DATAPATH.format(target_language, target_language, \"test\")\n",
    "test_data = pd.read_csv(test_path, sep = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the dataset into wordwise and characterwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:03:54.651731Z",
     "iopub.status.busy": "2022-05-07T14:03:54.651131Z",
     "iopub.status.idle": "2022-05-07T14:03:54.844734Z",
     "shell.execute_reply": "2022-05-07T14:03:54.843754Z",
     "shell.execute_reply.started": "2022-05-07T14:03:54.651640Z"
    }
   },
   "outputs": [],
   "source": [
    "#All unique characters\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "input_characters.add(' ')\n",
    "target_characters.add(' ')\n",
    "\n",
    "#Training Data\n",
    "train_input = [str(w) for w in train_data[1]]\n",
    "train_target = [\"\\t\" + str(w) + \"\\n\" for w in train_data[0]]\n",
    "for word in train_input:\n",
    "    for char in word:\n",
    "        input_characters.add(char)\n",
    "for word in train_target:\n",
    "    for char in word:\n",
    "        target_characters.add(char)\n",
    "\n",
    "#Validation Data\n",
    "dev_input = [str(w) for w in dev_data[1]]\n",
    "dev_target = [\"\\t\" + str(w) + \"\\n\" for w in dev_data[0]]\n",
    "for word in dev_input:\n",
    "    for char in word:\n",
    "        input_characters.add(char)\n",
    "for word in dev_target:\n",
    "    for char in word:\n",
    "        target_characters.add(char)\n",
    "\n",
    "#Test Data\n",
    "test_input = [str(w) for w in test_data[1]]\n",
    "test_target = [\"\\t\" + str(w) + \"\\n\" for w in test_data[0]]\n",
    "\n",
    "for word in test_input:\n",
    "    for char in word:\n",
    "        input_characters.add(char) \n",
    "for word in test_target:\n",
    "    for char in word:\n",
    "        target_characters.add(char)\n",
    "        \n",
    "#Sorting the characters\n",
    "input_characters = list(input_characters)\n",
    "target_characters = list(target_characters)\n",
    "input_characters.sort()\n",
    "target_characters.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching character and maximum sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:03:55.625922Z",
     "iopub.status.busy": "2022-05-07T14:03:55.624995Z",
     "iopub.status.idle": "2022-05-07T14:03:55.650914Z",
     "shell.execute_reply": "2022-05-07T14:03:55.648925Z",
     "shell.execute_reply.started": "2022-05-07T14:03:55.625875Z"
    }
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max(max([len(text) for text in train_input]),max([len(text) for text in dev_input]))\n",
    "max_encoder_seq_length = max(max_encoder_seq_length,max([len(text) for text in test_input]))\n",
    "                             \n",
    "max_decoder_seq_length = max(max([len(text) for text in train_target]),max([len(text) for text in dev_target]))\n",
    "max_decoder_seq_length = max(max_decoder_seq_length,max([len(text) for text in test_target]))\n",
    "                             \n",
    "print(\"Number of Training samples:\", len(train_input))\n",
    "print(\"Number of Validation samples:\", len(dev_input))\n",
    "print(\"Number of Test samples:\", len(test_input))\n",
    "                             \n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Indexing and Inverse Dictionary Indexing for the unique Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:03:56.965789Z",
     "iopub.status.busy": "2022-05-07T14:03:56.965406Z",
     "iopub.status.idle": "2022-05-07T14:03:56.972898Z",
     "shell.execute_reply": "2022-05-07T14:03:56.971540Z",
     "shell.execute_reply.started": "2022-05-07T14:03:56.965754Z"
    }
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "inverse_input_token_index = dict([(i, char) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "inverse_target_token_index = dict([(i, char) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Encoder-Decoder One Hot Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:03:57.859468Z",
     "iopub.status.busy": "2022-05-07T14:03:57.859184Z",
     "iopub.status.idle": "2022-05-07T14:03:58.738437Z",
     "shell.execute_reply": "2022-05-07T14:03:58.737518Z",
     "shell.execute_reply.started": "2022-05-07T14:03:57.859438Z"
    }
   },
   "outputs": [],
   "source": [
    "train_encoder_input_data = np.zeros((len(train_input), max_encoder_seq_length), dtype=\"float32\")\n",
    "train_decoder_input_data = np.zeros((len(train_input), max_decoder_seq_length), dtype=\"float32\")\n",
    "train_decoder_target_data = np.zeros((len(train_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "for i, (input_text, target_text) in enumerate(zip(train_input, train_target)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        train_encoder_input_data[i, t] = input_token_index[char]\n",
    "    train_encoder_input_data[i, t + 1 :] = input_token_index[' ']\n",
    "    for t, char in enumerate(target_text):\n",
    "        train_decoder_input_data[i, t] = target_token_index[char]\n",
    "        if t > 0:\n",
    "            train_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    train_decoder_input_data[i, t + 1 :] = target_token_index[' ']\n",
    "    train_decoder_target_data[i, t:, target_token_index[' ']] =  1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Encoder-Decoder One Hot Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:03:58.858871Z",
     "iopub.status.busy": "2022-05-07T14:03:58.858081Z",
     "iopub.status.idle": "2022-05-07T14:03:58.963216Z",
     "shell.execute_reply": "2022-05-07T14:03:58.961960Z",
     "shell.execute_reply.started": "2022-05-07T14:03:58.858808Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_encoder_input_data = np.zeros((len(dev_input), max_encoder_seq_length), dtype=\"float32\")\n",
    "dev_decoder_input_data = np.zeros((len(dev_input), max_decoder_seq_length), dtype=\"float32\")\n",
    "dev_decoder_target_data = np.zeros((len(dev_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "for i, (input_text, target_text) in enumerate(zip(dev_input, dev_target)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        dev_encoder_input_data[i, t] = input_token_index[char]\n",
    "    dev_encoder_input_data[i, t + 1 :] = input_token_index[' ']\n",
    "    for t, char in enumerate(target_text):\n",
    "        dev_decoder_input_data[i, t] = target_token_index[char]\n",
    "        if t > 0:\n",
    "            dev_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    dev_decoder_input_data[i, t + 1 :] = target_token_index[' ']\n",
    "    dev_decoder_target_data[i, t:, target_token_index[' '] ] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:03:59.665766Z",
     "iopub.status.busy": "2022-05-07T14:03:59.665441Z",
     "iopub.status.idle": "2022-05-07T14:03:59.698392Z",
     "shell.execute_reply": "2022-05-07T14:03:59.697510Z",
     "shell.execute_reply.started": "2022-05-07T14:03:59.665712Z"
    }
   },
   "outputs": [],
   "source": [
    "test_encoder_input_data = np.zeros((len(test_input), max_encoder_seq_length), dtype=\"float32\")\n",
    "for i, input_word in enumerate(test_input):\n",
    "    for t, char in enumerate(input_word):\n",
    "        test_encoder_input_data[i, t] = input_token_index[char]\n",
    "    test_encoder_input_data[i, t + 1 :] = input_token_index[' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordwise Inference Mechanism for Vanilla Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:04:01.476825Z",
     "iopub.status.busy": "2022-05-07T14:04:01.476050Z",
     "iopub.status.idle": "2022-05-07T14:04:01.520141Z",
     "shell.execute_reply": "2022-05-07T14:04:01.519122Z",
     "shell.execute_reply.started": "2022-05-07T14:04:01.476775Z"
    }
   },
   "outputs": [],
   "source": [
    "#Sigmoid Function\n",
    "def sigmoid(i):\n",
    "    return [1/(1 + np.exp(-z)) for z in i]\n",
    "\n",
    "# Vanilla_Inference Function\n",
    "def vanilla_inference(model, dev_encoder_input_data, dev_input, dev_target, num_decoder_tokens, max_decoder_seq_length, target_token_index, inverse_target_token_index, encoder_latent_dim, decoder_latent_dim, model_name):\n",
    "    \n",
    "    #Prediction Function --> Wordwise\n",
    "    def decode_sequence_predict(input_sequence):\n",
    "        # Encode the input as state vectors.\n",
    "        states_value = [encoder_model.predict(input_sequence)] * len(decoder_models_index)\n",
    "        # Generate empty target sequence of length 1.\n",
    "        target_sequence = np.zeros(( 1, 1))\n",
    "\n",
    "        # Populate the first character of target sequence with the start character.\n",
    "        target_sequence[0, 0 ] = target_token_index[\"\\t\"]\n",
    "        \n",
    "        flag = True\n",
    "        output_sequence = \"\"\n",
    "\n",
    "        while flag:\n",
    "            output = decoder_model.predict([target_sequence] + states_value)\n",
    "            output_tokens, states_value = output[0], output[1:]\n",
    "\n",
    "            # Sample a token\n",
    "            sample_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sample_chararcter = inverse_target_token_index[sample_token_index]\n",
    "            output_sequence += sample_chararcter\n",
    "            if sample_chararcter == \"\\n\" or len(output_sequence) > max_decoder_seq_length:\n",
    "                flag = False\n",
    "            target_sequence = np.zeros((1, 1))\n",
    "            target_sequence[0, 0] = sample_token_index \n",
    "        return output_sequence\n",
    "    \n",
    "    \n",
    "    no_of_encoder_layers = len(encoder_latent_dim)\n",
    "    encoder_embedding_index, encoder_models_index = -1, []\n",
    "    decoder_embedding_index, decoder_models_index = -1, []\n",
    "    dense_index = -1\n",
    "    encoder_layers_count = 0\n",
    "    \n",
    "    flag = True\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        print(layer.name)\n",
    "        # Dense Layer\n",
    "        if \"dense\" in layer.name :\n",
    "            dense_index = idx\n",
    "\n",
    "        # Embedding layer\n",
    "        if \"embedding\" in layer.name:\n",
    "            if flag:\n",
    "                encoder_embedding_index = idx\n",
    "                flag = False\n",
    "            else:\n",
    "                decoder_embedding_index = idx\n",
    "\n",
    "        # Encoder-Decoder Model Layers \n",
    "        if model_name.lower() in layer.name:\n",
    "            if encoder_layers_count < no_of_encoder_layers:\n",
    "                encoder_models_index.append(idx)\n",
    "                encoder_layers_count += 1\n",
    "            else:\n",
    "                decoder_models_index.append(idx)\n",
    "\n",
    "    \n",
    "    # Encoder Model\n",
    "    encoder_inputs = model.input[0]  # input_1\n",
    "\n",
    "    if model_name == \"RNN\" or model_name == \"GRU\":\n",
    "        encoder_outputs, state = model.layers[encoder_models_index[-1]].output\n",
    "        encoder_model = keras.Model(encoder_inputs, [state])\n",
    "    \n",
    "    elif model_name == \"LSTM\":\n",
    "        encoder_outputs, state_h_enc, state_c_enc = model.layers[encoder_models_index[-1]].output\n",
    "        encoder_model = keras.Model(encoder_inputs, [state_h_enc, state_c_enc])\n",
    "    \n",
    "    else:\n",
    "        print(\"Wrong Choice of Model...\")\n",
    "        return\n",
    "\n",
    "    #Decoder Model\n",
    "    decoder_inputs = model.input[1]  # input_2\n",
    "    decoder_outputs =  model.layers[decoder_embedding_index](decoder_inputs)\n",
    "\n",
    "    decoder_states_inputs =  []\n",
    "    decoder_states = []\n",
    "\n",
    "    # Decoder Models\n",
    "    for dec in range(len(decoder_latent_dim)):\n",
    "        \n",
    "        if model_name == \"RNN\" or model_name == \"GRU\":\n",
    "            state = keras.Input(shape = (decoder_latent_dim[dec], ))\n",
    "            current_states_inputs = [state]\n",
    "            decoder_outputs, state = model.layers[decoder_models_index[dec]](decoder_outputs, initial_state = current_states_inputs)\n",
    "            decoder_states += [state]\n",
    "\n",
    "        elif model_name == \"LSTM\":\n",
    "            state_h_dec, state_c_dec = keras.Input(shape = (decoder_latent_dim[dec],)),  keras.Input(shape = (decoder_latent_dim[dec],))\n",
    "            current_states_inputs = [state_h_dec, state_c_dec]\n",
    "            decoder_outputs, state_h_dec,state_c_dec = model.layers[decoder_models_index[dec]](decoder_outputs, initial_state = current_states_inputs)\n",
    "            decoder_states += [state_h_dec, state_c_dec]\n",
    "            \n",
    "        else:\n",
    "            print(\"Wrong Choice of Model...\")\n",
    "        \n",
    "        decoder_states_inputs += current_states_inputs\n",
    "\n",
    "    # Decoder Dense layer\n",
    "    decoder_dense = model.layers[dense_index]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Final decoder model\n",
    "    decoder_model = keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    #Count of correct Predictions\n",
    "    correct_count = 0\n",
    "    #File to Laod the Prediction\n",
    "    vanilla_prediction = open(\"/kaggle/working/predictions_vanilla.csv\", \"w\", encoding='utf-8')\n",
    "    vanilla_prediction.write(\"Input Sentence,Predicted Output Sentence,Original Target Sentence\\n\")\n",
    "    for idx in range(len(dev_input)):\n",
    "        if idx%50 == 0:\n",
    "            print(\"Test at: \", idx)\n",
    "        input_sequence = dev_encoder_input_data[idx : idx + 1]\n",
    "        decoded_word = decode_sequence_predict(input_sequence)\n",
    "        original_word = dev_target[idx][1:]\n",
    "        vanilla_prediction.write(dev_input[idx] + \",\" + decoded_word[:-1] + \",\" + original_word[:-1] + \"\\n\")\n",
    "        if(original_word == decoded_word):\n",
    "            correct_count += 1\n",
    "\n",
    "    return correct_count/len(dev_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Block to Train the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:04:02.714810Z",
     "iopub.status.busy": "2022-05-07T14:04:02.714504Z",
     "iopub.status.idle": "2022-05-07T14:59:42.007469Z",
     "shell.execute_reply": "2022-05-07T14:59:42.006404Z",
     "shell.execute_reply.started": "2022-05-07T14:04:02.714782Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "\n",
    "#Best Configuration\n",
    "hidden_layer_size=512\n",
    "num_encoder_layers=3\n",
    "num_decoder_layers=3\n",
    "learning_rate=0.001\n",
    "optimizer='nadam'\n",
    "batch_size=64\n",
    "model_name = \"LSTM\"\n",
    "embedding_size = 512\n",
    "dropout = 0.3\n",
    "epochs = 25\n",
    "beam_size = 0\n",
    "\n",
    "#Encoder Model\n",
    "encoder_inputs = keras.Input(shape=(None, ))\n",
    "encoder_outputs = keras.layers.Embedding(input_dim = num_encoder_tokens,\n",
    "                                        output_dim = embedding_size,\n",
    "                                        input_length = max_encoder_seq_length)(encoder_inputs)\n",
    "    \n",
    "encoder_latent_dim = [hidden_layer_size]*num_encoder_layers\n",
    "for latent_dim in encoder_latent_dim:\n",
    "    if model_name == \"RNN\":\n",
    "        encoder_outputs, state = keras.layers.SimpleRNN(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n",
    "        encoder_states = [state]\n",
    "    elif model_name == \"LSTM\":\n",
    "        encoder_outputs, state_h, state_c = keras.layers.LSTM(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n",
    "        encoder_states = [state_h, state_c]\n",
    "    elif model_name == \"GRU\":\n",
    "        encoder_outputs, state = keras.layers.GRU(latent_dim, dropout = dropout, return_state = True, return_sequences = True)(encoder_outputs)\n",
    "        encoder_states = [state]\n",
    "    else:\n",
    "        print(\"Wrong Choice of Model...\")\n",
    "\n",
    "#Decoder Model\n",
    "decoder_inputs = keras.Input(shape=(None, ))\n",
    "decoder_outputs = keras.layers.Embedding(input_dim = num_decoder_tokens,\n",
    "                                         output_dim = embedding_size, \n",
    "                                         input_length = max_decoder_seq_length)(decoder_inputs)\n",
    "\n",
    "decoder_latent_dim = [hidden_layer_size]*num_decoder_layers\n",
    "for latent_dim in decoder_latent_dim:\n",
    "    if model_name == \"RNN\":\n",
    "        decoder = keras.layers.SimpleRNN(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n",
    "        decoder_outputs, _ = decoder(decoder_outputs, initial_state = encoder_states)\n",
    "\n",
    "    elif model_name == \"LSTM\":\n",
    "        decoder = keras.layers.LSTM(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n",
    "        decoder_outputs, _, _ = decoder(decoder_outputs, initial_state = encoder_states)\n",
    "\n",
    "    elif model_name == \"GRU\":\n",
    "        decoder = keras.layers.GRU(latent_dim, dropout = dropout, return_sequences = True, return_state = True)\n",
    "        decoder_outputs, _= decoder(decoder_outputs, initial_state = encoder_states)\n",
    "    else:\n",
    "        print(\"Wrong Model Choice\")\n",
    "\n",
    "#Decoder Dense Layer\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Runnable Model\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n",
    "\n",
    "#Different Optimizers\n",
    "if optimizer == 'adam':\n",
    "    model.compile(optimizer = Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "elif optimizer == 'nadam':\n",
    "    model.compile(optimizer = Nadam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "elif optimizer == 'rmsprop':\n",
    "    model.compile(optimizer = RMSprop(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "else:\n",
    "    print(\"Wrong Optimizer Choice...\")\n",
    "        \n",
    "#Model fitting with train and validation data characterwise\n",
    "model.fit(\n",
    "    [train_encoder_input_data, train_decoder_input_data],\n",
    "    train_decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = ([dev_encoder_input_data, dev_decoder_input_data], dev_decoder_target_data),\n",
    ")\n",
    "model.save(\"Best_Model\")\n",
    "validation_accuracy = vanilla_inference(model, dev_encoder_input_data, dev_input, dev_target, num_decoder_tokens, max_decoder_seq_length, target_token_index, inverse_target_token_index, encoder_latent_dim, decoder_latent_dim, model_name)\n",
    "print(\"Wordlevel Validation Accuracy: \", validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy on the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:59:42.010065Z",
     "iopub.status.busy": "2022-05-07T14:59:42.009507Z",
     "iopub.status.idle": "2022-05-07T15:42:17.617237Z",
     "shell.execute_reply": "2022-05-07T15:42:17.616279Z",
     "shell.execute_reply.started": "2022-05-07T14:59:42.010011Z"
    }
   },
   "outputs": [],
   "source": [
    "test_accuracy = vanilla_inference(model, test_encoder_input_data, test_input, test_target, num_decoder_tokens, max_decoder_seq_length, target_token_index, inverse_target_token_index, encoder_latent_dim, decoder_latent_dim, model_name)\n",
    "print(\"Wordlevel Test Accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T15:42:17.621387Z",
     "iopub.status.busy": "2022-05-07T15:42:17.620485Z",
     "iopub.status.idle": "2022-05-07T15:42:17.644340Z",
     "shell.execute_reply": "2022-05-07T15:42:17.642204Z",
     "shell.execute_reply.started": "2022-05-07T15:42:17.621308Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/kaggle/working/predictions_vanilla.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T15:42:17.651521Z",
     "iopub.status.busy": "2022-05-07T15:42:17.649617Z",
     "iopub.status.idle": "2022-05-07T15:42:17.691817Z",
     "shell.execute_reply": "2022-05-07T15:42:17.690418Z",
     "shell.execute_reply.started": "2022-05-07T15:42:17.651468Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
